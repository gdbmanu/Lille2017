\documentclass{beamer}
\usecolortheme{whale}
\usecolortheme{orchid}
\useinnertheme[shadow=false]{rounded}
\useoutertheme[footline=authortitle]{miniframes}

\usepackage{multimedia}

\usepackage[french]{babel}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{multimedia}
\usepackage{amssymb}
\usepackage{amsmath}

\title[]
{Learning in actionable universes} 
%\subtitle{Day 1 : Encoding and signal processing with neural assemblies : definitions, models, simulations, experiments}

\author{Emmanuel Daucé}

\institute{Centrale Marseille, Marseille, France \\
Aix Marseille Univ, Inserm, INS, Institut de Neurosciences des Systèmes, Marseille, France}

\date{}

\begin{document}

\begin{frame}\titlepage
\end{frame}



\section{Introduction}
\subsection{}

\begin{frame}
	\tableofcontents[currentsection]
\end{frame}     

\begin{frame}\frametitle{Recommender systems vs. Biological control systems}
	\begin{center}
		\includegraphics[width=\linewidth]{figs/cap-frog-col.png}
	\end{center}
	\begin{columns}
		\begin{column}{.45 \linewidth}
			\begin{itemize}
				\item Online learning
				\item Large response set
				\item Context adaptation
				\item Frequent renewal
			\end{itemize}
		\end{column}
		\begin{column}{.45 \linewidth}
			\begin{block}{Main intuition}
				Labels are actions!
			\end{block}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}\frametitle{Labels vs. Actions}
	\begin{columns}
		
		\begin{column}{.48 \linewidth}
			{\bf Category learning :}
			\begin{itemize}
			\item Label = Latent variable
			\item The label $y$ is the \emph{cause} of observation $x$ 
			\item Generative models, Predictive coding, ...
			\end{itemize}
		\end{column}

		\begin{column}{.48 \linewidth}
			{\bf Action-based learning :}
			\begin{itemize}
			\item Label = Action
			\item The observation $x$ is the \emph{cause} of action $y$
			\item (and $y$ is possibly the cause of \emph{next} observation $x'$)
			\item Bandit models, POMDP, Active inference, ...
			\end{itemize}
		\end{column}
	\end{columns}
\begin{exampleblock}{}
	{\bf Assumption :} natural systems control is grounded on action-based learning.
\end{exampleblock}
\end{frame}

\begin{frame}\frametitle{Actionable universe (Bandit problem)}
	\begin{itemize}
		\item Repertoire of K possible \emph{actions} : 1, ..., K
		\item Learn the effect-of-action through a sequence of trial: $\tilde {y}_1$, ..., $\tilde{y}_t$, ...
		\item Every action $\tilde{y}_t$ brings an \textit{information} (feedback) $f_t$ 
		(which in turn provides a \textit{loss} $l_t$)
		\item Exploration/exploitation dilemma :
		\begin{itemize}
			\item (either) Better predict the effect-of-action $W_t \simeq P(f|\tilde{y})$
			\item (or) minimize regret $$ \sum_{t \in 1,..,T} l_t - l^*_t$$ 
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Contextual actionable universe (Online learning)}
%Processus d'apprentissage pour lequel se répètent les opérations suivantes~:
A sequential update~:
\begin{block}{}
For all $t \in 1,... T$~:
\begin{enumerate}
	\item Read a \emph{context} ${\color{red}x_t} \in \mathbb{R}^d$
	\item Choose a \emph{label} $\tilde{y}_t \in \{1,...,K\}$ %selon $\Pi_{t-1}$ (politique).
	\item Read feedback $f_t$
	\item Update model $W_t$
\end{enumerate}
\end{block}

Related problems :
\begin{itemize}
	\item Contextual bandits \cite{lai1985asymptotically,auer2002finite}
	\item Supervised online learning \cite{rosenblatt1958perceptron,duda1973pattern}
\end{itemize}

\end{frame}

\begin{frame}\frametitle{Role of feedback}
	\begin{block}{}
		The feedback/loss function interplay is at the core of learning.
	\end{block}
 \begin{itemize}
 	\item Bandit case : 
 	\begin{itemize}
 		\item quantitative feedback $f_t \in \mathbb{R}$
 		\item $f_t = -l_t$ relates to the direct outcome of action
 	\end{itemize}
 	\item Category learning~:
 	\begin{itemize}
 		\item A qualitative feedback :
 		\begin{itemize}
 			\item either explicit: $f_t = y_t$
 			\item or implicit: "good"/"bad" (reward) 
 		\end{itemize}
 		\item The loss $l_t$ is \textit{derived} from $f_t$.
 	\end{itemize}
 \end{itemize}
 
 
 
\end{frame}


\begin{frame}
	\frametitle{Binary guiding in multi-class classification}
	
	\begin{itemize}
		\item Binary feedback:
		\begin{itemize}
			\item "all-or-nothing" feedback
			\item clic, like, visit, follow, retweet ...
			\item very common in man-machine interaction
		\end{itemize}
		\item Unary coding / Binary guiding : 
		\begin{itemize}
			\item every $x_t$ (context) promotes a unique expected label $y_t$
			(any other response is a miss)
			\item The proposed label $\tilde{y}_t$
			\item $f_t = {\color{red}\delta(\tilde{y}_t ,y_t)} \in \{0,1\}$
		\end{itemize}
		\item Methods :
		\begin{itemize}
			\item "Banditron" \cite{kakade2008efficient}
			\item Contextual bandits
		\end{itemize}
	\end{itemize}
\end{frame}





%\begin{frame}
%	\frametitle{}
%	\begin{itemize}
%		\item Task : character recognition, face recognition etc.
%		\item Observation / observation space : $x  $ 
%		\item Labels : $1,...,K$
%		\item Linear assumption : 
%		\begin{itemize}
%			
%			\item Close according to $\langle .,. \rangle \leftrightarrow$ same label ?
%		\end{itemize}
%		\item One linear mapping for each label :
%		$$ W = (w_1, ..., w_K) \in \mathbb{R}^{Kd}$$
%		\item Similarity-based response (\textit{Winner-takes-all}):
%		$$ \hat{y} = \underset{k \in 1,...,K}{\text{argmax}}\langle w_k,x\rangle$$
%	\end{itemize}
%\end{frame}

\begin{frame}{Linear classifiers}
	Similarity measure $\langle .,. \rangle$ on observation space
	\begin{itemize}
		\item Multiclass : 
		\begin{itemize}
			\item Task : character recognition, face recognition etc.
			\item read $X_t = x_t \in \mathbb{R}^d$, find its category $y_t$
			\item Labels : $1,...,K$
			\begin{exampleblock}{}
				$
				\left.
				\begin{array}{l}
				W = (w_1,..,w_K) \in \mathbb{R}^{K d}\\
				X_t^k \triangleq (\vec{0}, ...,  x_t, ..., \vec{0}) \in \mathbb{R}^{K d}
				\end{array}
				\right\}
				\text{ so that : }
				\langle W, X^k_t\rangle = \langle w_k, x_t\rangle
				$	
			\end{exampleblock}	
		\end{itemize}
		\item Scoring/ranking : 
		\begin{itemize}
			\item read $X_t = (x_t^1, ..., x_t^K) \in \mathbb{R}^{Kd}$, identify best match $y$ to target
			\begin{exampleblock}{}
				$
				\left.
				\begin{array}{l}
				W = w \in \mathbb{R}^{d}\\
				X_t^k \triangleq x_t^k \in \mathbb{R}^{d}
				\end{array}
				\right\}
				\text{ so that : }
				\langle W, X^k_t\rangle = \langle w, x_t^k\rangle
				$	
			\end{exampleblock}	
		\end{itemize}
	\end{itemize}

\end{frame}

	

\begin{frame}
	\frametitle{The Banditron \cite{kakade2008efficient}}
%	inspiré du Perceptron multiclasse \cite{rosenblatt1958perceptron,duda1973pattern}
	\begin{small}
	Inspired by the multiclass perceptron \cite{rosenblatt1958perceptron,duda1973pattern}
	\begin{block}{}
		$\forall t \in 1,...,T :$
		\begin{align*}
		&\text{1. Read } 
		&& X_t 
		\\
		&\text{2. Choose :} 
		&& \hat{y}_t = \underset{k \in\{1,..,K\}}{\text{argmax}}  \langle W_{t-1}, X_t^k \rangle 
		\\
		& %\text{3. Décision }\tilde{y}_t\text{ : } 
		&& \tilde{y}_t \sim (1-\varepsilon) \delta(k,\hat{y}_t) + \frac{\varepsilon}{K} 
		\\	
		&\text{3. Read } 
		&& {\color{red} f_t = \delta(\tilde{y}_t ,y_t)}  
		\\
		&\text{4. Update :} 
		&& W_t = W_{t-1} + \frac{{\color{red}f_t}\cdot X_t^{\tilde{y}_t}}{P(\tilde{Y}_t=\tilde{y}_t)} - X_t^{\hat{y}_t} 
		\end{align*}
	\end{block}
		Regret : $O(T^{2/3})$; Non-sparse.
	\end{small}

\end{frame}

%\section{Modèles probabilistes}
%\subsection{}

\begin{frame}\frametitle{Banditron alternatives}
	\begin{itemize}
		\item Contextual bandits
		\item Choice based on :
		\begin{itemize}
			\item Confidence intervals (UCB)\cite{lai1985asymptotically}, LinUCB \cite{auer2002using}
			\item 2nd order Perceptron \cite{cesa2005second}
			\item Examples :
			\begin{itemize}
				\item\cite{li2010contextual}
				\item\cite{hazan2011newtron}
				\item\cite{crammer2013multiclass}
				\item\cite{ngo2013upper}
			\end{itemize}
		\end{itemize} 
		\item Regret $O(\sqrt{T})$ in the stationary case.
		\item The update relies on an estimator of
		$\mathbb{E}\left[ {X_t^{\hat{y}_t}}^T X_t^{\hat{y}_t}\right]$:
		\begin{itemize}
			\item  $O(d^2)$ cost in space
			\item Non sparse
		\end{itemize}
	\end{itemize}
	
\end{frame}


\begin{frame}\frametitle{Main question}
	\begin{itemize}
		\item Binary feedback: $f_t \in \{0,1\}$
		\begin{itemize}
			\item "all-or-nothing" feedback
			\item clic, like, visit, follow, retweet ...
		\end{itemize}
		\item Unary coding ("one-hot")/ Binary guiding : 
		\begin{itemize}
			\item every $x_t$ (context) promotes a unique expected label $y_t$
			(any other response is a miss)
		\end{itemize}
	\end{itemize}
	$\rightarrow$ The uniqueness of the expected label $y_t$ needs to be expressed in a loss function.
\end{frame}



\begin{frame}\frametitle{Classical label-aware online learning loss functions}
	Observation : $X$; expected label : ${\color{green}y}$; 
	\small
	\begin{columns}
		\begin{column}{.8\linewidth}
			\begin{footnotesize}
				\begin{itemize}
					\item Logistic loss:
					\begin{align*} 
					l &= - \log \frac{\exp \langle W, X^{\color{green}y} \rangle}{ \sum_{k=1}^K \exp\langle W, X^k\rangle}
					\end{align*}
					\item Hinge loss: 
					\begin{itemize}
						\item Relative loss (Kessler)~:
						$$l =  \left[ 1 -  \langle W, X^{\color{green}y} \rangle + \max_{k \neq y} \langle W, X^k\rangle\right]_+$$
						\item Absolute (One-Versus-All)~:
						$$l = \sum_{k=1}^K \left[1 + (1 - 2 \delta({\color{green}y},k)) \langle W, X^k\rangle\right]_+$$
					\end{itemize}
				\end{itemize}
			\end{footnotesize}			
		\end{column}
		\begin{column}{.2\linewidth}
			\centerline{\includegraphics[width=\linewidth]{figs/loss.png}}
		\end{column}	
	\end{columns}
	\normalsize
	
\end{frame}


\section{Contributions}

\subsection{Daucé, E, Proix, T, Ralaivola, L; proc. of IJCNN 2015}
\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame} 

\begin{frame}\frametitle{Policy gradient \cite{Wil92}}
	\small
	\begin{footnotesize}

	Model-free RL, POMDP, temporal credit assignment etc...

	\begin{itemize}
		\item Read $X$
		\item Stochastic policy : $\tilde{y} \sim \text{Multinomial}(\boldsymbol{\pi})$ with :
		\begin{columns}[b]
			\begin{column}{.35\linewidth}
				\begin{exampleblock}{}
					$$ \pi(k) = \frac{\exp\langle W, X^k\rangle}{\sum_{\ell}\exp\langle W, X^\ell\rangle}$$
				\end{exampleblock}
			\end{column}
			\begin{column}{.4\linewidth}
				\begin{exampleblock}{}
					$$ \pi(k) =  (1-\varepsilon) \delta(k,\hat{y}) + \frac{\varepsilon}{K} $$
				\end{exampleblock}
			\end{column}
			\begin{column}{.1\linewidth}
				\begin{exampleblock}{}
					etc.
				\end{exampleblock}
			\end{column}				
		\end{columns}
		
		
		\item Each response $\tilde{y} \sim \text{Multinomial}(\boldsymbol{\pi})$ provides a \emph{reward} ${\color{violet}r}$
	\end{itemize}
	    
    $\rightarrow$ find $W^*$ that maximizes the reward expectation :
		$$ W^*  = \text{argmax}_W \mathbb{E}({\color{violet}r})|_W$$
		using gradient ascent : 
		$$ W \leftarrow W + \eta \nabla_W \mathbb{E}({\color{violet}r})|_W $$
	\end{footnotesize}
	\normalsize
\end{frame}


\begin{frame}\frametitle{Policy gradient {\color{red} with binary guiding}}
	\begin{block}{}
		$\forall t \in 1,...,T :$
		\begin{align*}
		&\text{1. Read } 
		&& X_t 
		\\
		&\text{2. Choose :} 
		&& \forall k, \pi(k|X_t) = \frac{\exp\langle W_{t-1}, X_t^k\rangle}{\sum_{\ell}\exp\langle W_{t-1}, X_t^\ell\rangle}
		\\
		&
		&& \tilde{y}_t \sim \text{Multinomial}(\boldsymbol{\pi})
		\\
		&\text{3. Read } 
		&& {\color{red} f_t = \delta(\tilde{y}_t ,y_t)} 
		\\
		&
		&& {\color{violet}r_t} =  {\color{red} f_t} r^+ +(1-{\color{red} f_t}) r^-
		\\
		&\text{4. Update :} 
		&& W_t = W_{t-1} + \eta {\color{violet}r_t} \left(X_t^{\tilde{y}_t} - \sum_k \pi(k|X_t) X_t^k \right) 
		\end{align*}
	\end{block}	
	
\end{frame}

\begin{frame}{Main result}
	Let :
	\begin{itemize}
		\item ${\color{red}\tilde{y}}$ be the current response (random variable);
		\item ${\color{green}y}$ be the actual label associated with $X$
		\item $\boldsymbol{g}(X,{\color{red}\tilde{y}})) = {\color{violet}r_t} \left(X^{\tilde{y}_t} - \sum_k \pi(k|X) X^k \right)$ be the policy gradient
	\end{itemize}
	Then :
	\begin{exampleblock}{}
$$\mathbb{E}_{\tilde{\mathcal{Y}}|\mathcal{X} = X}(\boldsymbol{g}(X,{\color{red}\tilde{y}})) = \underbrace {(r^+ - r^-) \pi({\color{green}y}|X)}_\text{=1?}
\underbrace{\left(X^{\color{green}y} - \sum_k  \pi(k|X) X^k \right)}_\text{Logistic gradient}$$
	\end{exampleblock}	
\end{frame}	

\begin{frame}{Multiclass PG with binary guiding recipe}

	\begin{tiny}
		\begin{exampleblock}{}
			\begin{align*}
			\text{cov}_{\mathcal{X},\mathcal{Y}}(\boldsymbol{g}(X,{\color{red}\tilde{y}})) 
			=& \mathbb{E}_\mathcal{X} \left[ \left( r^- + (1-\pi({\color{green}y}|X) (r^+ - r^-) \right)^2 
				\frac{\pi({\color{green}y}|X)}{(1-\pi({\color{green}y}|X))} {\color{green}\boldsymbol{g}}(X)^T {\color{green}\boldsymbol{g}}(X)\right]\\
			&+ {r^-}^2 \mathbb{E}_\mathcal{X}\left[\tilde{\boldsymbol{\Sigma}}(X)\right]
			+ (r^+-r^-)^2 \text{cov}_\mathcal{X} \left[\frac{\pi({\color{green}y}|X)}{(1-\pi({\color{green}y}|X))}{\color{green}\boldsymbol{g}}(X)\right]
			\end{align*}
		\end{exampleblock}
	\end{tiny}	

	
Consider
\begin{itemize}
	\item $a = r^+ - r^-$ the reward "amplitude"
	\item $b \in [0,1]$ the reward "baseline" : $\left|\frac{r^+}{r^-}\right| = \frac{1-b}{b}$
\end{itemize}
Then with $\pi^+ = \mathbb{E}_\mathcal{X}(\pi({\color{green}y}|X))$:
\begin{itemize}
	\item Take $a =  \frac{1}{\pi^+}$ (logistic gradient "speed")
	\item Take $b =  \frac{\pi^+(1-\pi^+)}{1+\pi^+ - \frac{2}{K}}$ (variance reduction)
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Learning and forgetting : Regularized Policy gradient update}
	\vspace{-.8cm}
	\begin{itemize}
		\item Regularized optimization ($\lambda$ hyperparameter):
		\vspace{-.4cm} 
		$$\max _{\boldsymbol{W}} \mathcal{H} = \max _{\boldsymbol{W}} E(r) - \frac{\lambda}{2}||\boldsymbol{W}||^2$$
		\vspace{-.4cm}
		\item Regularized gradient ascent : 
		\footnotesize{$\nabla_W \mathcal{H} = {E}({\color{blue}r\nabla_W\ln\pi({\color{red}\tilde{y}}|X)}) - \lambda W$ }
		\begin{itemize}
			\item Gradient estimator (stochastic gradient) :
			\vspace{-.2cm} 
			$$
			% E(  r \nabla_\mathbf{w}\ln\pi(\underline{\mathbf{x}},y,\mathbf{w}) ) 
			%  \simeq 
			\left\langle {\color{blue}{\color{violet}r_t} \nabla_W\ln\pi({\color{red}\tilde{y}_t}|X_t)}\right\rangle_{1..T} $$
			\item Online update (learning rate $\eta << 1$):
			\vspace{-.2cm} 
			\begin{align}
			W &\leftarrow W + \eta ( {\color{blue}{\color{violet}r} \nabla_W\ln\pi({\color{red}\tilde{y}}|X)} - \lambda W) \nonumber \\
			&= (1 - \eta \lambda) W + \eta {\color{blue}{\color{violet}r} \nabla_W\ln\pi({\color{red}\tilde{y}}|X)} \nonumber
			\end{align}
		\end{itemize}
		\vspace{-.2cm}
		\item The old examples ``fade away'' as time passes
		$\rightarrow$ tracking algorithm and novelty detection (Kivinen et al, 2010)
	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Kernel extension}
\begin{exampleblock}{}
\footnotesize
\begin{align*}
&\text{4. Update :} 
&& W_t(.) = (1 - \eta \lambda) W_{t-1}(.) + \eta {\color{violet}r_t} \left(\mathcal{K}(X_t^{\tilde{y}_t},.) - \sum_k \pi(k|X_t) \mathcal{K}(X_t^k,.) \right) 
\end{align*}
\normalsize
\end{exampleblock}
Or :
\begin{exampleblock}{}
	$$W_t(.) = \sum_{u=1}^{t} \sum_{k=1}^K \alpha_{k,u} \beta_{t-u} \mathcal{K}(X^k_t,.)$$
\end{exampleblock}
	with : 
	$$ \alpha_{k,u} = \eta {\color{violet}r_u} (\delta({\color{red}\tilde{y}_u},k) - \pi(k|X_u;W_u))$$
	and
	$$
	\beta_v = (1-\eta\lambda)^v
	$$   
\end{frame}

\subsection{Zhong, H and Daucé, E, hal-01345825, submitted}

\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame} 


\begin{frame}\frametitle{Online empirical risk minimization}
	\footnotesize
	\begin{itemize}
		\item "Passive-agressive" approach \cite{crammer2006online}
		\item "Kessler" Hinge loss : $l_t =  \left[ 1 -  \langle W_{t-1}, X^{\color{green}y}_t \rangle + \max_{k \neq y} \langle W_{t-1}, X_t^k\rangle\right]_+$
		\item Local quadratic optimization : $\forall t$, solve: 
		$$W_{t} = \arg \min_W \frac{1}{2} \| W - W_{t-1}\|^2 + C \xi^2 \hbox{ s.t. } l_t \leq \xi$$
		\item Update~:
		$$W_{t} =  W_{t-1} + \frac{l_t}{2\|X_t\|^2 + \frac{1}{2C}}  (X_t^{y_t} - \max_{k \neq y_t} X_t^k)$$
		\item In the linearly separable case~:
		$$\sum_{t=1}^{T} l_t^2 \leqslant 4 R^2 \parallel{U}\parallel^2$$
	\end{itemize}
	\normalsize
\end{frame}


\begin{frame}\frametitle{Hinge loss: "Bandit" reduction}
	\begin{columns}
		\begin{column}{.2 \linewidth}
			\centerline{\includegraphics[width=\linewidth]{figs/cap-loss.png}}
		\end{column}
		\begin{column}{.8 \linewidth}
			\begin{itemize}
				\item Reduction (sample) of the OVA loss~: 
				$$l_t =  \left[1 + (1 - 2 {\color{red}\delta(y_t,\tilde{y}_t)}) \langle W_{t-1}, X_t^{\tilde{y}_t}\rangle\right]_+$$

				\item Online empirical risk minimization~:
				$$W_{t} =  W_{t-1} + \frac{l_t}{\|X_t\|^2 + \frac{1}{2C}}  (2 {\color{red}\delta(y_t,\tilde{y}_t)} - 1) X_t^{\tilde{y}_t}$$		
				\item Aggressiveness / conservatism ($C \rightarrow \infty$)~:
				\begin{itemize}
					\item "one-shot" update
					\item label-error sensitivity
				\end{itemize}	
			\end{itemize}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Bandit "Passive-Aggressive"  (BPA)}
%	\begin{exampleblock}{}
%		$
%		\left.
%		\begin{array}{l}
%		W = (w_1,..,w_K) \in \mathbb{R}^{K d}\\
%		X_t^k \triangleq (\vec{0}, ...,  x_t, ..., \vec{0}) \in \mathbb{R}^{K d}
%		\end{array}
%		\right\}
%		\text{ tels que : }
%		\langle W, X^k_t\rangle = \langle w_k, x_t\rangle
%		$
%		
%	\end{exampleblock}
	
	\begin{block}{}
		$\forall t \in 1,...,T :$
		\begin{align*}
		&\text{1. Read } 
		&& x_t 
		\\
		&\text{2. Choose :} 
		&& \hat{y}_t = \underset{k \in\{1,..,K\}}{\text{argmax}}  \langle W_{t-1}, X_t^k \rangle 
		\\
		& %\text{3. Décision }\tilde{y}_t\text{ : } 
		&& \tilde{y}_t \sim (1-\varepsilon) \delta(k,\hat{y}_t) + \frac{\varepsilon}{K} 
		\\	
		&\text{3. Read } 
		&& {\color{red} f_t = \delta(\tilde{y}_t ,y_t)}  
		\\
		&\text{4. Update :} 
		&& W_t = W_{t-1} + \frac{l_t}{\|X_t\|^2 + \frac{1}{2C}} (2{\color{red}f_t}-1)\cdot X_t^{\tilde{y}_t}
		\end{align*}
	\end{block}
	
\end{frame}

\begin{frame}{Linearly separable case}
	\begin{theorem}
		Let $(x_1,y_1),...,(x_T,y_T)$ be a sequence of separable examples where $x_t \in \mathbb{R}^d$, $y_t\in \{1,...,K\}$ and $\parallel x_t\parallel\leqslant R$ for all t, let $\tilde{y}_1,...,\tilde{y}_T$ be a sequence of responses, with $\tilde{y}_t\in \{1,...,K\}$, 
		and let $U \in \mathbb{R}^{K d}$ be such that $ \forall t, l^*_t=0$. Then, assuming $C \rightarrow \infty$, the cumulative squared loss of BPA is bounded by:
		\begin{equation}
		\sum_{t=1}^{T} l_t^2 \leqslant R^2 \parallel{U}\parallel^2
		\end{equation}
	\end{theorem}
	
	\begin{alertblock}{Warning!!}
		The squared loss sum is not here an upper bound of the number of classification errors.
	\end{alertblock}
\end{frame}

\begin{frame}{Additional conditions}
	Consider the greedy choice $\tilde{y}_t = \hat{y}_t = \underset{k \in\{1,..,K\}}{\text{argmax}}  \langle W_{t-1}, X_t^k \rangle$ ~:
	\begin{columns}
		\begin{column}{.74\linewidth}
			\begin{itemize}
				\item if all $X^k$'s $k$ belong to a convex set $\mathcal{C}_k \subset \mathbb{R}^d$
				\item If $\exists t^*$ so that $\forall t \geq t^*, l_t =0$
				\item If $\exists t \geq t^*$ so that $\tilde{y}_t = y_t = k$
			\end{itemize}
		\end{column}
		\begin{column}{.24\linewidth}
			\includegraphics[width=\linewidth]{figs/sep-convex.png}
		\end{column}
	\end{columns}
	
	then \textit{all} examples from $C_k$ are correctly classified for $t \geq t^*$.
	\vspace{.5cm}
	
	Moreover, this can be assumed almost surely if: 
	$$\tilde{y}_t \sim (1-\varepsilon) \delta(k,\hat{y}_t) + \frac{\varepsilon}{K} $$
	($\varepsilon$-greedy)
\end{frame}

\begin{frame}{Non-separable stationary case}
	\begin{footnotesize}
	\begin{theorem}

		Let $(x_1,y_1),...,(x_T,y_T)$ be a sequence of examples where $x_t \in \mathbb{R}^d$, $y_t\in \{1,...,K\}$ and $\parallel x_t \parallel\leqslant R$ for all t, let $\tilde{y}_1,...,\tilde{y}_T$ be a sequence of responses, with $\tilde{y}_t\in \{1,...,K\}$. Then for any  $U \in \mathbb{R}^{K d}$, and assuming $C \rightarrow \infty$, the cumulative squared loss of BPA is bounded by:
		\[\sum_{t=1}^{T}l_t^2 \leqslant \left(R\parallel{U}\parallel+2 \sqrt{\sum_{t=1}^{T}(l_t^{\ast})^2}\right)^2 \]
	\end{theorem}

	\begin{alertblock}{}
		\begin{itemize}
			\item For large $T$, the loss is at worst twice of the optimal loss 
			\item Needs a finite $C$ to reach an $O(\sqrt{T})$ regret
		\end{itemize}
	\end{alertblock}
	\end{footnotesize}
\end{frame}

\begin{frame}{Kernel extension}

\begin{block}{}
	\small
	\begin{align*}
		\text{4. Update :} 
		&& W_t(.) = W_{t-1}(.) + \frac{l_t}{\mathcal{K}(X_t,X_t) + \frac{1}{2C}} (2{\color{red}f_t}-1)\cdot \mathcal{K}(X_t^{\tilde{y}_t},.)
	\end{align*}
	\normalsize
\end{block}

Or :
\begin{exampleblock}{}
	$$W_t(.) = \sum_{u=1}^{t} \alpha_u  \mathcal{K}(X_t^{\tilde{y}_u},.)$$
\end{exampleblock}
with : 
$$ \alpha_{u} = \frac{l_u}{\mathcal{K}(X_u,X_u) + \frac{1}{2C}} (2{\color{red}f_u}-1)
$$


\end{frame}

\section{Numerical experiments}
\subsection{Zhong, H and Daucé, E, hal-01345825, submitted}

\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame} 

\begin{frame}{Datasets}
	\begin{table}[h]
		\caption{Five datasets considered, with $n$ the number of instances, $d$ the vectors dimension and $K$ the number of labels.}
		\label{table:mce}
		\begin{center}
			\begin{tabular}{l l l l}
				{\bf Dataset}  & {\bf $n$} & {\bf $d$} & {\bf $K$}\\
				\hline
				SynSep & $10^5$ 	& 400 	& 9 \\
				
				SynNonSep & $10^5$ & 400 	& 9 \\
				
				RCV1-v2  & $10^5$ 	& 47236 	& 53 \\
				
				Segment & 2310	& 19	& 7	\\
				
				Pendigits 	& 7494	& 16	& 10	\\
			\end{tabular}
		\end{center}
	\end{table}
\end{frame}

\begin{frame}{Parameters}
	\begin{small}
	\begin{table}[h]
		\caption{Parameters setting for different algorithms and different datasets. }
		% {\bf P} stands for Perceptron, {\bf PA} for Passive Agressive, {\bf B} for Banditron, {\bf C} for Confidit, {\bf BPA} for the one-Bit feedback Passive Aggressive (algorithm 1), {\bf K-B} for the kernel Banditron, {\bf K-BPA}  for the kernel  realization of BPA (algorithm 1) and {\bf K-SGD} for the kernel  realization of SGD (algorithm 2).}
		%\label{table:bpa}
		%\begin{center}
		
		%		\begin{tabular}{llllll}
		%			
		%			\hline
		%			{\bf }  & {\bf P} & {\bf PA } & {\bf B}& {\bf C} & {\bf BPA}\\
		%			\hline
		%			SS & $\varnothing$ & $C=0$ & $\varepsilon = 0.014$ &$\eta = 10^3$ & $\varepsilon = 0.4$\\
		%			&&&&& $C = \infty$\\
		%			
		%			SN & $\varnothing$ & $C=10^{-2}$ & $\varepsilon =0.65$ & $\eta = 10^3$& $\varepsilon = 0.8$\\
		%			&&&&& $C = 10^{-2}$\\			
		%			R & $\varnothing$ & $C=10^{-2}$ & $\varepsilon =0.4$ & $\eta = 10^2$ & $\varepsilon = 0.2$\\
		%			&&&&& $C = 10^{-2}$\\
		%			\hline
		%			&{\bf KB} & {\bf BPA} & {\bf KBPA} &{\bf KSGD}\\
		%			\hline
		%			P & $\sigma = 1$ & $C = 10^{-2}$ &$\sigma = 1$&$\sigma = 1$\\
		%			&&$\varepsilon = 0.2$& $C = 1$ & $H = 500$\\
		%			&&& $\varepsilon = 0.2$ &\\
		%			S & $\sigma = 10$ & $C = 10^{-2}$ & $\sigma = 10$&$\sigma = 10$\\
		%			&&$\varepsilon = 0.2$& $C = 1$& $H = 200$\\
		%			&&& $\varepsilon = 0.2$ &
		%			%LR(26 letters) & null &  $C=0.1$ & $\varepsilon = 0.2$& $\eta=10^2$ & $\varepsilon = 0.8,C= 1$ \\
		%			
		%			%LR(10 numbers) & null & $C=0.1$ & $\varepsilon= 0.4$& $\eta = 10$ & $\varepsilon = 0.6,C=1$\\
		%			
		%		\end{tabular}
		%\hspace{-.8cm}
		\begin{center}
			\begin{tabular}{llllll}
				
				\hline
				{\bf Dataset}  & {\bf P} & {\bf PA } & {\bf B}& {\bf C} & {\bf BPA}\\
				\hline
				Synsep & $\varnothing$ & $C\rightarrow\infty$ & $\varepsilon = 0.014$ &$\eta = 10^3$ & $\varepsilon = 0.4$\\
				&&&&& $C \rightarrow \infty$\\
				
				SynNonSep & $\varnothing$ & $C=10^{-2}$ & $\varepsilon =0.65$ & $\eta = 10^3$& $\varepsilon = 0.8$\\
				&&&&& $C = 10^{-2}$\\			
				RCV1-v2 & $\varnothing$ & $C=10^{-2}$ & $\varepsilon =0.4$ & $\eta = 10^2$ & $\varepsilon = 0.2$\\
				&&&&& $C = 10^{-2}$\\
				\hline
				&{\bf K-B} & {\bf BPA} & {\bf K-BPA} &{\bf K-SGD}\\
				\hline
				Segment & $\sigma = 1$ & $\varepsilon = 0.3$ & $\sigma = 1$ &$\sigma = 1$\\
				&$\varepsilon =0.1$&&$\varepsilon = 0.3$ & $H = 200$\\
				Pendigits & $\sigma = 10$ & $\varepsilon = 0.3$ &$\sigma = 10$&$\sigma = 10$\\
				&$\varepsilon =0.1$&& $\varepsilon = 0.3$ & $H = 500$\\
				
				%LR(26 letters) & null &  $C=0.1$ & $\varepsilon = 0.2$& $\eta=10^2$ & $\varepsilon = 0.8,C= 1$ \\
				
				%LR(10 numbers) & null & $C=0.1$ & $\varepsilon= 0.4$& $\eta = 10$ & $\varepsilon = 0.6,C=1$\\	
			\end{tabular}	
		\end{center}
	\end{table}
	\end{small}
\end{frame}

\begin{frame}{Exploration rate}
	%\begin{figure}[htp]
		%\centerline{\bf (a)}
		\begin{columns}
			\begin{column}{.5\linewidth}
				\centerline{\includegraphics[width=\linewidth]{figs/SynNonSep_gamma.eps}}
				%\centerline{\bf (b)}
			\end{column}
			\begin{column}{.5\linewidth}
				\centerline{\includegraphics[width=\linewidth]{figs/Reuters_gamma.eps}}
			\end{column}	
		\end{columns}
		
		\begin{itemize}
			\item Final error rate in function of $\varepsilon$
			\item SynNonSep (left) and Reuters (right) datasets.
		\end{itemize}
		%\end{figure}
		
		%\begin{figure}[ht!]
		
		%\caption{Taux d'erreur moyen du Banditron et du BPA en fonction du taux d'exploration $\varepsilon$ }
		%\label{pic:BPARCVerr}
	%\end{figure}
\end{frame}

\begin{frame}{SynSep Cumulative errors }
			
	\centerline{
		\includegraphics[width=.7\linewidth]{figs/SynSep.eps}
	}
	
			
	\begin{footnotesize}
		\begin{itemize}
			\item Perceptron, PA, Banditron, Confidit and BPA
			\item 9 classes, $d = 400$
		\end{itemize}
	\end{footnotesize}
	
\end{frame}

\begin{frame}{SynNonSep Cumulative errors }
	
			\centerline{
				\includegraphics[width=.7\linewidth]{figs/SynNonSep.eps}
			}
	
	\begin{footnotesize}
		\begin{itemize}
			\item Perceptron, PA, Banditron, Confidit and BPA
			\item 9 classes, $d = 400$
		\end{itemize}
	\end{footnotesize}
	
\end{frame}

\begin{frame}{Reuters Cumulative errors}
	

			\centerline{
				\includegraphics[width=.7\linewidth]{figs/RCV1_v2_53class.eps}}
	
	
	\begin{footnotesize}
		\begin{itemize}
			\item Perceptron, PA, Banditron, Confidit and BPA
			\item 53 classes, $d = 47236$
		\end{itemize}
	\end{footnotesize}
	
\end{frame}

\begin{frame}{Segment (with Kernels)}
	\begin{columns}[t]
		\begin{column}{.5\linewidth}

	\includegraphics[width=\linewidth]{figs/Segment_kernel_T.png}

		\end{column}
		\begin{column}{.5\linewidth}

		\includegraphics[width=\linewidth]{figs/Segment_kernel_CM.png}


		\end{column}	
	\end{columns}
	
		\begin{footnotesize}
			\begin{itemize}
				\item BPA, K-BPA, K-SGD, K-Banditron
				\item 7 classes, $d = 19$
			\end{itemize}
		\end{footnotesize}
\end{frame}


\begin{frame}{Pendigits (with Kernels)}
	\begin{columns}[t]
		\begin{column}{.5\linewidth}
			\includegraphics[width=\linewidth]{figs/Pendigits_kernel_T.png}			
		\end{column}
		\begin{column}{.5\linewidth}
				\includegraphics[width=\linewidth]{figs/Pendigits_kernel_CM.png}
		\end{column}	
	\end{columns}
	\begin{footnotesize}
		\begin{itemize}
			\item BPA, K-BPA, K-SGD, K-Banditron
			\item 10 classes, $d = 16$
		\end{itemize}
	\end{footnotesize}
\end{frame}

\subsection{Daucé, E, Proix, T, Ralaivola, L; proc. of IJCNN 2015}
\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame} 

\begin{frame} \frametitle{P300 speller}
	\vspace{-.3cm}
\footnotesize
	\begin{itemize}
		\item EEG : 
		\vspace{-.1cm}		
		\begin{itemize}
			\item 10 - 60 channels (surface electric potential - H Berger, 1929)
			\item high temporal resolution / low spatial resolution
			\item noisy, non-reliable,... ``Evoqued potentials'' technique
			\item the ``P300'' ERP is ``surprise'' effect (``oddball'' paradigm)
		\end{itemize}
	\end{itemize}
	\vspace{-.3cm}
	\begin{columns}
		\begin{column}{0.75\linewidth}
			\begin{itemize}
				\item P300-speller (Farwell and Donchin, 1988):
				\begin{itemize}
					\item based on the ``oddball'' paradigm
					\item 6 x 6 letters grid
					\item random row/column magnification (every 150-300 ms)
					\item row/column evidence build-up + argmax choice
					\item low SNR / low bit rate (many flashes for one letter)
					\item spelling accuracy tends to decrease in the long run
				\end{itemize}
			\end{itemize}
		\end{column}
		\begin{column}{0.25\linewidth}
			\centerline{
				\includegraphics[width=\linewidth]{figs/P300_grid.png}
			}
		\end{column}
	\end{columns}
\normalsize
\end{frame}

\begin{frame}\frametitle{EEG data (from Inserm U1028, Lyon, France)}
	\includegraphics[width=\linewidth]{figs/EEG.png}
\end{frame}

\begin{frame}\frametitle{Data processing pipeline}

	\centerline{
		\includegraphics[width=.9\linewidth]{figs/overview.png}
	}
\end{frame}

\begin{frame}{Rewards in classifiction}

	\begin{itemize}

		\item Online stochastic classifier :
		\begin{itemize}
			\item read input observations set : $X = (\boldsymbol{x}_1,...,\boldsymbol{x}_K)$
			\item give a score to every class : $\forall k, \pi(k|X;W) =  \frac{\exp\langle W, X^k\rangle}
			{\sum_{\ell}  \exp\langle W, X^\ell\rangle}$ 
			\item choose the response at random (Softmax choice)
			\item read the \emph{reward} $r$
			\item update $W$
		\end{itemize}
		\item Which reward ?
		\begin{itemize}
			\item ``error'' potential after the classifier's response:
			\centerline{\includegraphics[width=0.7\linewidth]{figs/online_P300.pdf}}
			\item ``BACKSPACE'' key on the virtual keyboard
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Softmax/Argmax spelling improvement}
	\centerline{\includegraphics[width=0.7\linewidth]{figs/PG_softmax.png}}
\end{frame}

%\begin{frame}\frametitle{XDAWN spatial filter}
%	\vspace{-.8cm}
%	\cite{Rivet09}
%	\centerline{
%		\includegraphics[width=0.7\linewidth]{ijcnn-eeg-filt}
%	}
%\end{frame}

\begin{frame}\frametitle{Classification improvement after a 25-trials training session}
	%\vspace{-1cm}
	\centerline{
		\includegraphics[width=.9\linewidth]{figs/fig_filter_adapt}
	}
\end{frame}

\begin{frame}\frametitle{Global recovery after electrode break
	}
	\centerline{
		\includegraphics[width=0.9\linewidth]{figs/fig_invalid}
	}
\end{frame}

\begin{frame}\frametitle{Individual recovery, label noise = 10\%}
	\centerline{
		\includegraphics[width=0.7\linewidth]{figs/ijcnn-subj-break-n01}
	}
\end{frame}

\begin{frame}\frametitle{Individual recovery, label noise = 30\%}
	\centerline{
		\includegraphics[width=0.7\linewidth]{figs/ijcnn-subj-break-n03}
	}
\end{frame}


\section{Conclusion}
\subsection{}
\begin{frame}
	\tableofcontents[currentsection]
\end{frame} 

\begin{frame}{Conclusion}
\footnotesize
	\begin{columns}
		\begin{column}{.5\linewidth}
			{\bf Policy gradient}
			\begin{exampleblock}{Pros}
				\begin{itemize}
					\item Cheap (linear cost)
					\item Neural networks / Multinomial generative friendly (logistic gradient)
					\item Label noise resistance
					\item 2nd order expandable
				\end{itemize}				
			\end{exampleblock}		
			\begin{alertblock}{Cons}
				\begin{itemize}
					\item Non-sparse
					\item $\eta, \lambda$ parameter fitting 
				\end{itemize}				
			\end{alertblock}		
		\end{column}
		\begin{column}{.5\linewidth}
			{\bf  OVA online quadratic optimization}
			\begin{exampleblock}{Pros}
				\begin{itemize}
					\item Cheap (linear cost)
					\item Sparse
					\item Upper bound when linearly separable
				\end{itemize}						
			\end{exampleblock}						
			\begin{alertblock}{Cons}
				\begin{itemize}
					\item Aggressive update $\rightarrow$ label noise sensitivity
					\item Needs an optimal "stiffness" $C$ hyperparameter (cross-validated)
					\item Non deterministic : needs an $\varepsilon$ (possibly decreasing)
				\end{itemize}				
			\end{alertblock}		
		\end{column}
	\end{columns}
\normalsize
%	\begin{itemize}
%		\item Passive Aggressive Bandit feedback~:
%		\begin{itemize}
%			\item Une information d'étiquetage limitée (1-bit)
%			\item Un apprentissage actif (par sondage) sur l'espace des labels 
%			\item Principe d'aversion à l'erreur (OVA)
%			\item Minimisation en ligne du risque empirique (optimisation quadratique locale sous contraintes)
%		\end{itemize} 
%		\item La perte au carré est bornée dans le cas linéairement séparable
%		\item Des conditions raisonnables de redondance des données assurent un classification correcte en environnement stationnaire
%		\item Parcimonie
%		\item Facile à mettre en œuvre
%		\item Passage à l'échelle OK (coût linéaire en espace)
%	\end{itemize}
\end{frame}

%\begin{frame}{Conclusion}
%	\begin{itemize}
%		\item Passive Aggressive Bandit feedback~:
%		\begin{itemize}
%			\item Une information d'étiquetage limitée (1-bit)
%			\item Un apprentissage actif (par sondage) sur l'espace des labels 
%			\item Principe d'aversion à l'erreur (OVA)
%			\item Minimisation en ligne du risque empirique (optimisation quadratique locale sous contraintes)
%		\end{itemize} 
%		\item La perte au carré est bornée dans le cas linéairement séparable
%		\item Des conditions raisonnables de redondance des données assurent un classification correcte en environnement stationnaire
%		\item Parcimonie
%		\item Facile à mettre en œuvre
%		\item Passage à l'échelle OK (coût linéaire en espace)
%	\end{itemize}
%\end{frame}

%\begin{frame}{Remarques}
%	\begin{alertblock}{Un résultat contre intuitif}
%		\begin{itemize}
%		\item Agressivité / one shot / parcimonie:
%		\begin{itemize}
%			\item En principe : réponse exagérée au bruit de label
%			\item Mise à jour sous-optimale dans les environnements stochastiques (bandit)
%		\end{itemize}  
%		\item L'aggressivité de l'algorithme nécessite d'être atténuée par un paramètre de "raideur" $C$
%			\begin{itemize}
%				\item $\rightarrow$ Regret en $O(\sqrt{T})$ dans le cas stationnaire
%				\item Bonne résistance au bruit de label
%			\end{itemize}
%		\item Sous-échantillonnage d'un problème sur-contraint
%		\end{itemize}
%	\end{alertblock}
%	
%	\begin{exampleblock}{Mise en oeuvre pratique}
%		\begin{itemize}
%		\item Validation croisée pour $C$ (valeur spécifique au problème)
%		\item Faire décroître $\varepsilon$ au cours du temps.
%		\end{itemize}
%	\end{exampleblock}
%		
%\end{frame}

\begin{frame}{Open questions}
	
	\begin{itemize}
		\item Unary coding + binary guiding :
		\begin{itemize}
			\item a more structured/constrained bandit problem
			\item multiclass gradient, multiclass bounds
		\end{itemize}
		\item Adversarial case :
		\begin{itemize}
			\item the more robust, the less sparse?
			\item learning and forgetting (tracking)
		\end{itemize}
     \end{itemize}
\end{frame}

\begin{frame}\frametitle{More "challenging" open questions}
	\begin{itemize}
		\item Learning in:
			\begin{itemize}
				\item embedded controllers
				\item real time
				\item many decisions in limited time/limited resources
				\item non-stationary environments
			\end{itemize}
		\item Binary guiding in nature :
\centerline{\includegraphics[width=.4\linewidth]{figs/cap-frog.png}}		
		\begin{itemize}
			\item Label = actions?
			\item Many actions = many labels
			\item Complex motor realization space (many DOFs)
			\item All or nothing
		\end{itemize}
		
	\end{itemize}
	
%	\begin{itemize}
%		\item Vers un apprentissage moins agressif? Basé sur un modèle?
%		\begin{itemize}
%			\item Moindre parcimonie
%			\item Risque de sensibilité au déséquilibre de classe (OVA)
%			\item Borne d'erreur plus difficile à prouver
%		\end{itemize}  
%		\item Extension aux environnements de jeux/avec adversaire :
%		\begin{itemize}
%			\item Extension au cas non-stationnaires \cite{kivinen2004online} 
%			\item Coups multiples, récompense différée (temporal credit assignment) \cite{sutton1998reinforcement}
%			\item IHM, personal computing, compagnons,..
%		\end{itemize}  		
%		\item Continuum entre l'apprentissage supervisé et l'apprentissage par renforcement?
%	\end{itemize}
%	\vspace{-.7cm}
%	\begin{columns}[t]
%		\begin{column}{.01\linewidth}
%		\end{column}
%		\begin{column}{.4\linewidth}
%			\begin{small}
%			\begin{itemize}
%				\item Cas des labels multiples
%				\item Un "crédit" d'information entre 1 et $K$?
%			\end{itemize} 
%			\end{small}
%		\end{column}
%		\begin{column}{.4\linewidth}
%			\begin{block}{}
%				\centerline{\includegraphics[width=\linewidth]{figs/cap-frog.png}}
%			\end{block}
%		\end{column}
%	\end{columns}
%	

		
\end{frame}

\bibliographystyle{apalike}
\bibliography{lille2017}
\end{document}